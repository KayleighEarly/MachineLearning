{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43236660",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "#     TO RUN ->                               #\n",
    "#     Click \"Cell\" in the above toolbar       #\n",
    "#        -> Select \"Run All\" from the menu    #\n",
    "#                                             #\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e70e45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "Toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "Toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.\n",
    "</script>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaccc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard machine learning libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd                # dataframe library\n",
    "pd.set_option('display.width', 950)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np                 # math library\n",
    "import matplotlib.pyplot as plt    # figure plotting\n",
    "\n",
    "# Classification Model libraries\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Web Libraries\n",
    "import urllib\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Interactinve Dashboard\n",
    "import functools\n",
    "import qgrid\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, HBox, VBox, Layout, Label\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24f11d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set into pandas dataframe\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/KayleighEarly/MachineLearning/main/notebooks/data/labeled_trail_data.csv\")\n",
    "\n",
    "# Identify features columns and target column\n",
    "X = df.drop(['Cluster Labels','url'], axis=1)\n",
    "y = df['Cluster Labels']\n",
    "\n",
    "# Setting the objects to category \n",
    "for c in X.select_dtypes(include='object'):\n",
    "    X[c] = X[c].astype('category')\n",
    "\n",
    "# Split the data, keeping 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e84716a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def load_existing_model():\n",
    "    clf = pickle.load(urllib.request.urlopen(\"https://raw.githubusercontent.com/KayleighEarly/MachineLearning/main/notebooks/models/gbm_model_1.pkl\"))\n",
    "\n",
    "    return clf\n",
    "\n",
    "# load existing model\n",
    "clf = load_existing_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04a44ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       "#wrap {\n",
       "   width:950px;\n",
       "   margin:0px;\n",
       "}\n",
       "</style>\n",
       "<div id=\"wrap\">\n",
       "<table style=\"width:950px\">\n",
       "    <tr>\n",
       "        <td colspan=\"2\" style=\"text-align:center\"><h1>Classification Model Training</h1></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"width:500px; padding-top:10px; padding-right:50px;\">\n",
       "            <p>By default, this dashboard is loaded with a pre-trained model hosted on \n",
       "            <a href=\"https://github.com/KayleighEarly/MachineLearning/blob/main/notebooks/models/gbm_model_1.pkl\">\n",
       "            GitHub</a>. To retrain the model, please click the \"Retrain Model\" button at the end of the section.</p>\n",
       "            <p>The dataset being used for the model contains the columns (features) explained in the table to the \n",
       "            right.</p>\n",
       "        </td>\n",
       "        <td>\n",
       "            <table>\n",
       "                <tr>\n",
       "                    <th>Feature</th>\n",
       "                    <th>Description</th>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>url</td>\n",
       "                    <td>the FQDN the data was scraped from</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>difficulty</td>\n",
       "                    <td>the avg reported difficult of the trails</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>dist</td>\n",
       "                    <td>the length of the trail (miles)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>type</td>\n",
       "                    <td>the type of trail (loop, point to point, out and back, lollipop)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>high_elev</td>\n",
       "                    <td>the highest elevation reached in the trail (ft)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>low_elev</td>\n",
       "                    <td>the lowest elevation reached in the trail (ft)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>elev_gain</td>\n",
       "                    <td>the total elevation gained across the trail (ft)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>elev_lost</td>\n",
       "                    <td>the total elevation lost across the trail (ft)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>grade_avg</td>\n",
       "                    <td>the average grade of the trail (degrees)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>grade_max</td>\n",
       "                    <td>the maximum grade of the trail (degrees)</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td>Cluster Labels</td>\n",
       "                    <td>the cluster group the trail belongs to (from 0 to 11)</td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style type=\"text/css\">\n",
    "#wrap {\n",
    "   width:950px;\n",
    "   margin:0px;\n",
    "}\n",
    "</style>\n",
    "<div id=\"wrap\">\n",
    "<table style=\"width:950px\">\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align:center\"><h1>Classification Model Training</h1></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width:500px; padding-top:10px; padding-right:50px;\">\n",
    "            <p>By default, this dashboard is loaded with a pre-trained model hosted on \n",
    "            <a href=\"https://github.com/KayleighEarly/MachineLearning/blob/main/notebooks/models/gbm_model_1.pkl\">\n",
    "            GitHub</a>. To retrain the model, please click the \"Retrain Model\" button at the end of the section.</p>\n",
    "            <p>The dataset being used for the model contains the columns (features) explained in the table to the \n",
    "            right.</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>Feature</th>\n",
    "                    <th>Description</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>url</td>\n",
    "                    <td>the FQDN the data was scraped from</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>difficulty</td>\n",
    "                    <td>the avg reported difficult of the trails</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>dist</td>\n",
    "                    <td>the length of the trail (miles)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>type</td>\n",
    "                    <td>the type of trail (loop, point to point, out and back, lollipop)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>high_elev</td>\n",
    "                    <td>the highest elevation reached in the trail (ft)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>low_elev</td>\n",
    "                    <td>the lowest elevation reached in the trail (ft)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>elev_gain</td>\n",
    "                    <td>the total elevation gained across the trail (ft)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>elev_lost</td>\n",
    "                    <td>the total elevation lost across the trail (ft)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>grade_avg</td>\n",
    "                    <td>the average grade of the trail (degrees)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>grade_max</td>\n",
    "                    <td>the maximum grade of the trail (degrees)</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Cluster Labels</td>\n",
    "                    <td>the cluster group the trail belongs to (from 0 to 11)</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</div>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1839d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"wrap\">\n",
       "    <center><p><h1>Model Accuracy</h1></p></center>\n",
       "    <p>The model shows a high level of accuracty, over 99% in default accuracy scoring, as well as\n",
       "    over a 99% ROC AOC score for both One-vs-One and One-vs-Rest scores. Further, the confusion \n",
       "    matrix shows a low level of confusion across the model and a classification report shows high \n",
       "    overall precision and accuracy across all of the clusters.</p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<div id=\"wrap\">\n",
    "    <center><p><h1>Model Accuracy</h1></p></center>\n",
    "    <p>The model shows a high level of accuracty, over 99% in default accuracy scoring, as well as\n",
    "    over a 99% ROC AOC score for both One-vs-One and One-vs-Rest scores. Further, the confusion \n",
    "    matrix shows a low level of confusion across the model and a classification report shows high \n",
    "    overall precision and accuracy across all of the clusters.</p>\n",
    "</div>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0053b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf3172551b44b3b55e38a4d4d1bb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), layout=Layout(width='950px'), _titles={'0': 'Accuracy Scores', '1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def check_model_accuracy(clf, X, y, X_train, X_test, y_train, y_test, accuracy_out):\n",
    "def check_model_accuracy():\n",
    "    \n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    macro_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\",\n",
    "                                      average=\"macro\")\n",
    "    weighted_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\",\n",
    "                                         average=\"weighted\")\n",
    "    macro_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\",\n",
    "                                      average=\"macro\")\n",
    "    weighted_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\",\n",
    "                                         average=\"weighted\")\n",
    "\n",
    "    with accuracy_out:\n",
    "        accuracy_out.clear_output()\n",
    "        \n",
    "        # print the default accuracy scores on training and test set\n",
    "        print('Training Set Accuracy: {:.2f}%'.format(clf.score(X_train, y_train) * 100))\n",
    "        print('Test Set Accuracy: {:.2f}%'.format(clf.score(X_test, y_test) * 100))\n",
    "        print('')\n",
    "\n",
    "        # Taking too long on binder, can be run locally\n",
    "        # print the cross validation accuracy score\n",
    "        #print('Cross-Validated Accuracy: {:.2f}%'.format(np.mean(cross_val_score(clf, X, y)) * 100))\n",
    "        #print('')\n",
    "\n",
    "        # print ROC/AUC scores\n",
    "        print(\"One-vs-One ROC AUC scores:\\n{:.4f}% (macro),\\n{:.4f}% \"\n",
    "              \"(weighted by prevalence)\"\n",
    "              .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "        print(\"One-vs-Rest ROC AUC scores:\\n{:.4f}% (macro),\\n{:.4f}% \"\n",
    "              \"(weighted by prevalence)\"\n",
    "              .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))\n",
    "\n",
    "#def check_classification_report(X_test, y_test, class_report_out):\n",
    "def check_classification_report():\n",
    "    # Classification Report\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    with class_report_out:\n",
    "        class_report_out.clear_output()\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "#def check_confusion_matrix(clf, X_test, y_test, confusion_out):\n",
    "def check_confusion_matrix():\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    with confusion_out:\n",
    "        confusion_out.clear_output()\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        fig = plt.figure(figsize=(8, 7))\n",
    "        ax = plt.subplot()\n",
    "        sns.heatmap(cm, annot=True, ax = ax, fmt = 'g')\n",
    "\n",
    "        # Label matrix\n",
    "        ax.set_xlabel('Predicted', fontsize=20)\n",
    "        ax.xaxis.set_label_position('bottom')\n",
    "        ax.xaxis.tick_bottom()\n",
    "        ax.set_ylabel('True', fontsize=20)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.title('Confusion Matrix', fontsize=20)\n",
    "        plt.show()\n",
    "                \n",
    "accuracy_out = widgets.Output()\n",
    "class_report_out = widgets.Output()\n",
    "confusion_out = widgets.Output()\n",
    "\n",
    "tabs = widgets.Tab(children=[accuracy_out, class_report_out, confusion_out], \n",
    "                  layout=Layout(width=\"950px\"))\n",
    "tabs.set_title(0, 'Accuracy Scores')\n",
    "tabs.set_title(1, 'Classification Rpt')\n",
    "tabs.set_title(2, 'Confusion Matrix')\n",
    "\n",
    "display(tabs)\n",
    "\n",
    "check_model_accuracy()\n",
    "check_classification_report()\n",
    "check_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f94b6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values take too long to process on Binder. Uncomment if running locally\n",
    "#HTML('''\n",
    "#<div id=\"wrap\">\n",
    "#    <center><p><h2>Feature Impact on Model</h2></p></center>\n",
    "#    <p>As shown in the bar graph below, of the 9 features, 8 had an impact on the classification prediction, \n",
    "#    with 7 of them having a high impact. This means that the clusters are both distinguishable and informed \n",
    "#    by the majority of input.</p>\n",
    "#</div>\n",
    "#''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c98ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def check_feature_impact():\n",
    "#    feature_out.clear_output()\n",
    "#    \n",
    "#    # Clean Up first\n",
    "#    explainer = shap.TreeExplainer(clf)\n",
    "#    shap_values = explainer.shap_values(X)\n",
    "#\n",
    "#    with feature_out:\n",
    "#        shap.summary_plot(shap_values, X, plot_size=(12,7))\n",
    "#    \n",
    "#feature_out = widgets.Output(layout={'width': '1000px'})\n",
    "#display(feature_out)\n",
    "#\n",
    "#check_feature_impact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9accc21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"wrap\">\n",
       "    <center><p><h2>Model Retraining</h2></p></center>\n",
       "    <p>The classification model can be retrained using the available labled data by clicking the \"Retrain \n",
       "    Model\" button below. Please be aware that this will take a while to complete, and will refresh \n",
       "    all accuracy and feature outputs.</p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<div id=\"wrap\">\n",
    "    <center><p><h2>Model Retraining</h2></p></center>\n",
    "    <p>The classification model can be retrained using the available labled data by clicking the \"Retrain \n",
    "    Model\" button below. Please be aware that this will take a while to complete, and will refresh \n",
    "    all accuracy and feature outputs.</p>\n",
    "</div>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6916bcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dfb7ae427445e08e0e09c009713f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Retrain Model', icon='check', style=ButtonStyle(), tooltip='Retrain Classif…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retrain_eventhandler(event):\n",
    "    # disable button and update output to say training\n",
    "    retrain.disabled=True\n",
    "    with retrain_out:\n",
    "        retrain_out.clear_output()\n",
    "        print('Model retraining... please wait.')\n",
    "    \n",
    "    # clear existing accuracy stats\n",
    "    accuracy_out.clear_output()\n",
    "    class_report_out.clear_output()\n",
    "    confusion_out.clear_output()\n",
    "    feature_out.clear_output()\n",
    "    \n",
    "    # retrain model\n",
    "    clf = train_model()\n",
    "    with retrain_out:\n",
    "        retrain_out.clear_output()\n",
    "        print('Model trained... updating accuracy metrics.')\n",
    "    \n",
    "    # update outputs\n",
    "    check_model_accuracy()\n",
    "    check_confusion_matrix()\n",
    "    check_classification_report()\n",
    "    check_feature_impact()\n",
    "    \n",
    "    with retrain_out:\n",
    "        retrain_out.clear_output()\n",
    "        print('Retrain complete.')\n",
    "    \n",
    "    retrain.disabled=False\n",
    "        \n",
    "        \n",
    "retrain = widgets.Button(\n",
    "    description='Retrain Model',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Retrain Classification model',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "retrain_out = widgets.Output()\n",
    "retrain.on_click(retrain_eventhandler)\n",
    "\n",
    "HBox([retrain, retrain_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "980b01e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"wrap\">\n",
       "    <center><p><h1>Recommendation Engine</h1></p></center>\n",
       "    <p>This is where the trained model can be used to make recommendations to users. The user can adjust \n",
       "    the various inputs to match the type of trail they have enjoyed previously and the model will attempt to\n",
       "    match the statistics with a cluster and will update the dataframe with related trails. Due to the fact \n",
       "    that there are thousands of trails per cluster, the application will limit output to only displaying \n",
       "    a maximum of 50 trails.</p>\n",
       "    <p>The user then has the additional option of filtering the cluster based on required criteria, for example \n",
       "    only trails that are loops, or have distance of less than 2 miles. This will refine the trails displayed in \n",
       "    the dataframe, again to a maximum of 50 trails.</p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<div id=\"wrap\">\n",
    "    <center><p><h1>Recommendation Engine</h1></p></center>\n",
    "    <p>This is where the trained model can be used to make recommendations to users. The user can adjust \n",
    "    the various inputs to match the type of trail they have enjoyed previously and the model will attempt to\n",
    "    match the statistics with a cluster and will update the dataframe with related trails. Due to the fact \n",
    "    that there are thousands of trails per cluster, the application will limit output to only displaying \n",
    "    a maximum of 50 trails.</p>\n",
    "    <p>The user then has the additional option of filtering the cluster based on required criteria, for example \n",
    "    only trails that are loops, or have distance of less than 2 miles. This will refine the trails displayed in \n",
    "    the dataframe, again to a maximum of 50 trails.</p>\n",
    "</div>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "361d0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_type = widgets.Dropdown(\n",
    "    options=['Loop', 'Point to Point', 'Out and Back', 'Lollipop', 'Unknown'],\n",
    "    value='Loop',\n",
    ")\n",
    "\n",
    "difficulty = widgets.Dropdown(\n",
    "    options=['Easy', 'Easy/Intermediate', 'Intermediate', 'Intermediate/Difficult', 'Difficult', 'Very Difficult'],\n",
    "    value='Easy',\n",
    ")\n",
    "\n",
    "dist = widgets.IntSlider(\n",
    "    min=-0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    value=4\n",
    ")\n",
    "elev_low = widgets.IntSlider(\n",
    "    min=-1250,\n",
    "    max=19700,\n",
    "    step=10,\n",
    "    value=2740\n",
    ")\n",
    "elev_high = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=16150,\n",
    "    step=10,\n",
    "    value=3310\n",
    ")\n",
    "elev_gain = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=14500,\n",
    "    step=10,\n",
    "    value=590\n",
    ")\n",
    "elev_lost = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=14500,\n",
    "    step=10,\n",
    "    value=430\n",
    ")\n",
    "avg_grade = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=14,\n",
    "    step=1,\n",
    "    value=3\n",
    ")\n",
    "max_grade = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=42,\n",
    "    step=1,\n",
    "    value=10\n",
    ")\n",
    "calculate = widgets.Button(\n",
    "    description='Find Trails',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click me',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "prediction_out = widgets.Output(layout={'width':'950px', 'border': '1px solid black'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8b1c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eventhandler(event) :\n",
    "    X_new = pd.DataFrame(columns=['difficulty', 'dist', 'type', 'high_elev', 'low_elev', 'elev_gain', \n",
    "                           'elev_lost', 'grade_avg', 'grade_max'])\n",
    "    trail_stats = {'difficulty': difficulty.value, 'dist': dist.value, 'type': trail_type.value, \n",
    "                   'high_elev': elev_high.value, 'low_elev': elev_low.value, 'elev_gain': elev_gain.value, \n",
    "                   'elev_lost': elev_lost.value, 'grade_avg': avg_grade.value, 'grade_max': max_grade.value}\n",
    "    X_new = X_new.append(trail_stats, ignore_index=True)\n",
    "        \n",
    "    X_new['dist'] = X_new['dist'].astype(float)\n",
    "    X_new['high_elev'] = X_new['high_elev'].astype(float)\n",
    "    X_new['low_elev'] = X_new['low_elev'].astype(float)\n",
    "    X_new['elev_gain'] = X_new['elev_gain'].astype(float)\n",
    "    X_new['elev_lost'] = X_new['elev_lost'].astype(float)\n",
    "    X_new['grade_avg'] = X_new['grade_avg'].astype(int)\n",
    "    X_new['grade_max'] = X_new['grade_max'].astype(int)\n",
    "    \n",
    "    # Setting the objects to category \n",
    "    for c in X_new.select_dtypes(include='object'):\n",
    "        X_new[c] = X_new[c].astype('category')\n",
    "\n",
    "    pred = clf.predict(X_new)\n",
    "    df_cluster = df.loc[df['Cluster Labels'] == pred[0]]\n",
    "    df_cluster.drop(['Cluster Labels'],axis=1,inplace=True)\n",
    "    df_cluster.set_index('url', inplace=True)\n",
    "\n",
    "    with prediction_out:\n",
    "        prediction_out.clear_output()\n",
    "        display(qgrid.show_grid(df_cluster))\n",
    "        \n",
    "calculate.on_click(calculate_eventhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "891bbe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712a6dd8b06048a6a382f93974c143e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Trail Type'), Label(value='Trail Difficulty'), Label(value='Distanc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfa405c6f0c4a5d8cd3075a11cbd88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Find Trails', icon='check', style=ButtonStyle(), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ec6b3653d642e7bd54040b37ceed2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', width='950px'), outputs=({'output_type': 'display_data', 'data'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels1 = VBox([Label('Trail Type'),Label('Trail Difficulty'),Label('Distance (miles)'),Label('Average Grade (degrees)')\n",
    "                ,Label('Maximum Grade (degrees)')])\n",
    "widgets1 = VBox([trail_type, difficulty, dist, avg_grade, max_grade])\n",
    "labels2 = VBox([Label('Lowest Elevation (ft)'),Label('Highest Elevation (ft)'),Label('Elevation Gained (ft)')\n",
    "                ,Label('Elevation Lost (ft)')])\n",
    "widgets2 = VBox([elev_low, elev_high, elev_gain, elev_lost])\n",
    "\n",
    "display(HBox([labels1, widgets1, labels2, widgets2]))\n",
    "\n",
    "display(calculate)\n",
    "display(prediction_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
